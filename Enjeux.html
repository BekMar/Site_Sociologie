<!DOCTYPE html>
<html lang="en" dir="ltr">

<head>
  <meta charset="utf-8">
  <title></title>
  <style media="screen">
    body {
      background-color: #dbe6fd;
    }

    hr {
      background-color: white;
      border-style: none;
      height: 2px;
      width: 100px;
    }

    html {
      text-align: center;
    }

    h1 {
      color: #233e8b;
    }

    h2 {
      color: #6e7582;
    }

    h3 {
      color: #6e7582;
    }

    h4 {
      color: #6e7582;
    }
  </style>
  <link rel="stylesheet" href="css/styles.css">
</head>

<body>
  <h2><strong>4. Enjeux et perspectives des scores dans les nouvelles
      technologies</strong></h2>

  <p>A travers la présentation de ces différentes interprétations des scores, il ressort de la conférence de Laurence Barry que les scores n’ont pas nécessairement un sens universel. Selon la conférencière, ces derniers
    découlent d’une probabilité épistémique et subjective de l’observateur, ce qui signifie qu’il existe une dépendance entre l’obtention du score et ses conditions de production. En effet, il n’existe aucun modèle de
    calcul qui soit ontologique et objectif, qui aurait donc un regard extérieur lors de l’observation d’un sujet.

    Mettons en lumière le fait que cette réflexion est importante à l’heure où les travaux sur l’intelligence artificielle alimentée par le big data se multiplient. L’intelligence artificielle (IA) peut en effet obtenir de
    meilleurs scores grâce aux inépuisables masses de données que représente le Big data. En effet, l’on peut penser que plus le nombre de données traitées par l’IA est important, plus l’analyse de cette dernière sera fine
    et ainsi plus sa décision sera certaine et proche de la réalité. Cette pensée peut conduire à une tendance à faire confiance aux IA ainsi alimentées par le Big Data.
    Selon Laurence Barry, « les données massives qui alimentent les nouveaux algorithmes visent d’une certaine manière à rendre compte quantitativement de cet « état de l’univers » : n’est-ce pas exactement cela
    qu’il s’agit quand on reproche aux données de reproduire les biais sociaux ». Lorsqu’elle dit cela, elle met en garde contre le fait que les IA alimentées par un grand nombre de données, vont se baser uniquement sur le
    score, et donc sur un paramètre que l'on pourrait qualifier de majoritaire. En effet, un « biais social » désigne l’influence qu’a la majorité sur une décision.
    Dès lors, baser une décision uniquement sur des scores issus de l’analyse de la Big Data et faire confiance de façon absolue à une IA ainsi alimentée par ces scores peut poser des problèmes notamment
    éthiques dans certains domaines.
    Par exemple, utiliser l’IA dans le domaine médical, pour prendre une décision sur un diagnostic et sur un traitement à administrer. En effet, dans le domaine médical, une IA pourrait prendre une décision
    non-adaptée à un patient particulier. Ledit patient peut présenter une pathologie inconnue ou peu connue, sur laquelle l’IA a très peu voire aucune donnée, et ainsi considérer que le patient est atteint d’une telle pathologie
    et lui administrer le traitement correspondant, alors que ce traitement ne serait en réalité pas adapté à la pathologie du patient. Un autre problème qui peut se poser, serait que l’IA pour administrer un traitement, se
    baserait sur l’état des connaissances, et refuserait d’utiliser un traitement nouveau sur lequel elle n’aurait pas assez de connaissances, mais qui pourtant pourrait mieux soigner le patient qu’un traitement plus connu. L’IA
    ne pourra ainsi jamais remplacer la capacité de décision que peut avoir un médecin personne physique, qui lui, en fonction de ses connaissances propres, de ses croyances, et des analyses et recherches qu’il fera lorsqu’il se
    trouvera face à un cas qu’il ne connaît pas ou sur lequel il doute, prendra une décision plus individualisée et sans doute plus pertinente.
    De la même manière, il est possible d’envisager l’application de l’intelligence artificielle dans le domaine juridique et judiciaire. Ainsi, évoquons les legaltechs et la justice prédictive. Les legaltech ont vocation
    à créer une base de données réunissant toutes les décisions de justice, afin par la suite de les compiler et de créer des scores issus de leur analyse. Or les scores étant peu fiables sur les cas particuliers, selon ce qu’il
    ressort de la conférence de Laurence Barry, si une machine prend une décision sur la base du score issu de la compilation de toutes les décisions de justice, cette décision ne sera pas nécessairement adaptée à un
    justiciable particulier.

    En outre, notons que le législateur européen a compris les enjeux que posent les décisions automatiques prises par des machines grâce notamment à l’analyse de la Big Data et des scores sur les
    individus.
    En effet, le RGPD pose des obligations liées à l’utilisation d’algorithmes pour prendre des décisions administratives individuelles. Dans un tel cadre, la personne qui fait l’objet d’une décision automatisée doit
    bénéficier d'une double information. Cette information concerne dans un premier temps le fait qu'elle fait l'objet d'une telle décision prise grâce à un algorithme. Et dans un second temps, si la personne concernée en
    fait la demande, l’information doit lui être donnée quant à la nature de l'algorithme qui a pris la décision c’est-à-dire la façon dont l’algorithme a été écrit, le calcul utilisé par la machine pour prendre la décision. La
    personne concernée peut également contester la décision prise par la machine et demander une intervention humaine pour infirmer, confirmer ou modifier la décision ainsi prise.
    <br>
    <br>
  <p>Le législateur européen semble ainsi peu faire confiance aux technologies décisionnelles basées sur des algorithmes et 100% automatisées, même si ces algorithmes sont basés sur un nombre important de données. Il a ainsi prévu la possibilité dans
    une telle situation, de faire intervenir toutefois un humain dans la prise de décision, et ainsi personnaliser la décision grâce non plus à un score global, mais aux connaissances et
    à la sensibilité d’une personne humaine et individuelle.</p>
</body>

</html>
